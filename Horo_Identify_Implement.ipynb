{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "with open('dataset0730.json' , 'r') as reader:\n",
    "    jf = json.loads(reader.read())\n",
    "num_data = len(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20963"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ†4/12é¡ (ä¸€å±¤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "four = [{'é­”','æ‘©','ç¾¯','â™‘','ç‰›','é‡‘ç‰›','ğŸ‚','ğŸ®','â™‰','è™•å¥³','â™'},\\\n",
    "        {'ç“¶','æ°´ç“¶','â™’','é›™å­','â™Š','ç§¤','å¤©ç§¤','âš–ï¸','â™'},\\\n",
    "        {'é­š','é›™é­š','ğŸŸ','ğŸ ','â™“','èŸ¹','å·¨èŸ¹','ğŸ¦€ï¸','â™‹','è ','å¤©è ','ğŸ¦‚ï¸','â™'},\\\n",
    "        {'ç¾Š','ç‰¡ç¾Š','ğŸ‘','â™ˆ','ç…','ğŸ¦ï¸','â™Œ','å°„æ‰‹','ğŸ¹ï¸','â™'}]\n",
    "\n",
    "twelve = [{'é­”','æ‘©','ç¾¯','â™‘'},{'ç“¶','æ°´ç“¶','â™’'},{'é­š','é›™é­š','ğŸŸ','ğŸ ','â™“'},\\\n",
    "          {'ç¾Š','ç‰¡ç¾Š','ğŸ‘','â™ˆ'},{'ç‰›','é‡‘ç‰›','ğŸ‚','ğŸ®','â™‰'},{'é›™å­','â™Š'},\\\n",
    "          {'èŸ¹','å·¨èŸ¹','ğŸ¦€ï¸','â™‹'},{'ç…','ğŸ¦ï¸','â™Œ'},{'è™•å¥³','â™'},\\\n",
    "          {'ç§¤','å¤©ç§¤','âš–ï¸','â™'},{'è ','å¤©è ','ğŸ¦‚ï¸','â™'},{'å°„æ‰‹','ğŸ¹ï¸','â™'}]\n",
    "\n",
    "def mapping(char, numC):\n",
    "    if numC==4:\n",
    "        for i in range(4):\n",
    "            if char in four[i]:\n",
    "                return i\n",
    "    elif numC==12:\n",
    "        for i in range(12):\n",
    "            if char in twelve[i]:\n",
    "                return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horoNorm1(inp): # æ‘©ç¾¯-->ç¾¯ã€é­šğŸŸ-->é­š\n",
    "    if len(inp & {'æ‘©', 'é­”', 'ç¾¯', 'â™‘'}) > 1:\n",
    "        inp = inp - {'æ‘©', 'é­”', 'â™‘'}\n",
    "    if len(inp & {'ç“¶','â™’'}) > 1:\n",
    "        inp = inp - {'â™’'}\n",
    "    if len(inp & {'é­š','ğŸŸ','ğŸ ','â™“'}) > 1:\n",
    "        inp = inp - {'ğŸŸ','ğŸ ','â™“'}\n",
    "    if len(inp & {'ç¾Š','ğŸ‘','â™ˆ'}) > 1:\n",
    "        inp = inp - {'ğŸ‘','â™ˆ'}\n",
    "    if len(inp & {'ç‰›','ğŸ‚','ğŸ®','â™‰'}) > 1:\n",
    "        inp = inp - {'ğŸ‚','ğŸ®','â™‰'}\n",
    "    if len(inp & {'é›™å­','â™Š'}) > 1:\n",
    "        inp = inp - {'â™Š'}\n",
    "    if len(inp & {'èŸ¹','ğŸ¦€ï¸','â™‹'}) > 1:\n",
    "        inp = inp - {'ğŸ¦€ï¸','â™‹'}\n",
    "    if len(inp & {'ç…','ğŸ¦ï¸','â™Œ'}) > 1:\n",
    "        inp = inp - {'ğŸ¦ï¸','â™Œ'}\n",
    "    if len(inp & {'è™•å¥³','â™'}) > 1:\n",
    "        inp = inp - {'â™'}\n",
    "    if len(inp & {'ç§¤','âš–ï¸','â™'}) > 1:\n",
    "        inp = inp - {'âš–ï¸','â™'}\n",
    "    if len(inp & {'è ','ğŸ¦‚ï¸','â™'}) > 1:\n",
    "        inp = inp - {'ğŸ¦‚ï¸','â™'}\n",
    "    if len(inp & {'å°„æ‰‹','ğŸ¹ï¸','â™'}) > 1:\n",
    "        inp = inp - {'ğŸ¹ï¸','â™'}      \n",
    "    return  inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horoNorm2(inp): # çµ±ä¸€åç¨±\n",
    "    if inp == {'é­”'} or inp == {'æ‘©'} or inp == {'â™‘'}:\n",
    "        inp = {'ç¾¯'}\n",
    "    elif inp == {'æ°´ç“¶'} or inp == {'â™’'}:\n",
    "        inp = {'ç“¶'}\n",
    "    elif inp == {'é›™é­š'} or inp == {'ğŸŸ'} or inp == {'ğŸ '} or inp == {'â™“'}:\n",
    "        inp = {'é­š'}\n",
    "    elif inp == {'ç‰¡ç¾Š'} or inp == {'ğŸ‘'} or inp == {'â™ˆ'} or inp == {''}:\n",
    "        inp = {'ç¾Š'}\n",
    "    elif inp == {'é‡‘ç‰›'} or inp == {'ğŸ‚'} or inp == {'ğŸ®'} or inp == {'â™‰'}:\n",
    "        inp = {'ç‰›'}\n",
    "    elif inp == {'â™Š'}:\n",
    "        inp = {'é›™å­'}\n",
    "    elif inp == {'å·¨èŸ¹'} or inp == {'ğŸ¦€ï¸'} or inp == {'â™‹'} or inp == {''}:\n",
    "        inp = {'èŸ¹'}\n",
    "    elif inp == {'ğŸ¦ï¸'} or inp == {'â™Œ'}:\n",
    "        inp = {'ç…'}\n",
    "    elif inp == {'â™'}:\n",
    "        inp = {'è™•å¥³'}\n",
    "    elif inp == {'å¤©ç§¤'} or inp == {'âš–ï¸'} or inp == {'â™'}:\n",
    "        inp = {'ç§¤'}\n",
    "    elif inp == {'å¤©è '} or inp == {'ğŸ¦‚ï¸'} or inp == {'â™'}:\n",
    "        inp = {'è '}\n",
    "    elif inp == {'ğŸ¹ï¸'} or inp == {'â™'}:\n",
    "        inp = {'å°„æ‰‹'}\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify1_1(data, num_class):\n",
    "    first = {}\n",
    "    for ID in data:    \n",
    "        reg = re.compile(r'(é­”|æ‘©|ç¾¯|â™‘|ç“¶|â™’|é­š|ğŸŸ|ğŸ |â™“|ç¾Š|ğŸ‘|â™ˆ|ç‰›|ğŸ‚|ğŸ®|â™‰|é›™å­|â™Š|èŸ¹|ğŸ¦€ï¸|â™‹|ç…|ğŸ¦ï¸|â™Œ|è™•å¥³|â™|ç§¤|âš–ï¸|â™|è |ğŸ¦‚ï¸|â™|å°„æ‰‹|ğŸ¹ï¸|â™).*(ç”·|å¥³).*(é­”|æ‘©|ç¾¯|â™‘|ç“¶|â™’|é­š|ğŸŸ|ğŸ |â™“|ç¾Š|ğŸ‘|â™ˆ|ç‰›|ğŸ‚|ğŸ®|â™‰|é›™å­|â™Š|èŸ¹|ğŸ¦€ï¸|â™‹|ç…|ğŸ¦ï¸|â™Œ|è™•å¥³|â™|ç§¤|âš–ï¸|â™|è |ğŸ¦‚ï¸|â™|å°„æ‰‹|ğŸ¹ï¸|â™).*(ç”·|å¥³)')\n",
    "        output = reg.findall(data[ID]['title'])\n",
    "        if len(output)!=0 and output[0][1]!=output[0][3] : # different gender            \n",
    "            # print(data[a]['title'])\n",
    "            if data[ID]['gender']==\"F\":\n",
    "                ans = output[0][output[0].index(\"å¥³\")-1]\n",
    "            else:\n",
    "                ans = output[0][output[0].index(\"ç”·\")-1]\n",
    "            # print (data[a]['id'])\n",
    "            # print (a, data[a]['gender'], output[0],\"-->\", ans, mapping (ans, num_class))\n",
    "            # first[str(data[a]['id'])]=[]\n",
    "            # first[str(data[a]['id'])].append(data[a])\n",
    "            # first[str(data[a]['id'])].append(mapping(ans, num_class))\n",
    "            first[str(data[ID]['id'])] = mapping(ans, num_class)\n",
    "    return first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify1_2(data, num_class):\n",
    "    second = {}\n",
    "    reg = re.compile(r'(é­”|æ‘©|ç¾¯|â™‘|ç“¶|â™’|é­š|ğŸŸ|ğŸ |â™“|ç¾Š|ğŸ‘|â™ˆ|ç‰›|ğŸ‚|ğŸ®|â™‰|é›™å­|â™Š|èŸ¹|ğŸ¦€ï¸|â™‹|ç…|ğŸ¦ï¸|â™Œ|è™•å¥³|â™|ç§¤|âš–ï¸|â™|è |ğŸ¦‚ï¸|â™|å°„æ‰‹|ğŸ¹ï¸|â™)')\n",
    "    reg_tag = re.compile(r'(ç¾¯|ç“¶|é­š|ç¾Š|ç‰›|é›™å­|èŸ¹|ç…|è™•å¥³|ç§¤|è |å°„æ‰‹)')\n",
    "    for ID in data:\n",
    "        output = set(reg.findall(jf[ID]['title']))\n",
    "        output = horoNorm1(output)\n",
    "        if len(output)==1:\n",
    "            output = horoNorm2(output)\n",
    "            another = list(output)\n",
    "            together = \" \".join(jf[ID]['topics'])\n",
    "            tags = set(reg_tag.findall(together))            \n",
    "            if len(tags)==2:\n",
    "                sign = tags - set(another)\n",
    "                ans = list(sign)[0]\n",
    "                # print (a, jf[a]['title'], ans, mapping(ans, num_class))\n",
    "                second[str(data[ID]['id'])] = mapping(ans, num_class)\n",
    "                if len(jf[ID]['content'])<30:\n",
    "                    print (jf[ID]['id'])\n",
    "    return second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SenBySen(sep):\n",
    "    notme = {\"å¦\",\"å‹\",\"ä»»\",\"é–ƒ\",\"æ–¹\",\"åª½\",\"çˆ¸\",\"å“¥\",\"å§Š\",\"å¼Ÿ\",\"å¦¹\",\"å…¬\",\"å©†\",\"å¥¹\",\"ä»–\",\"å®¶\",\"æœ\",\"é‡\"}\n",
    "    reg = re.compile(r'(æˆ‘|è‡ªå·±|æœ¬äºº|æœ¬èº«|æœ¬é­¯|å°å¼Ÿ|é­¯å¼Ÿ|å°å¦¹|é­¯å¦¹|å°å¥³å­|åŸpo|åœ¨ä¸‹|å¶)(.*)?æ˜¯(.*)?(æ‘©|é­”|ç¾¯|ç“¶|é­š|ğŸŸ|ğŸ |ç¾Š|ğŸ‘|ç‰›|ğŸ®|ğŸ‚|é›™å­|èŸ¹|ğŸ¦€ï¸|ç…|ğŸ¦ï¸|è™•å¥³|ç§¤|âš–ï¸|è |ğŸ¦‚ï¸|å°„æ‰‹|ğŸ¹ï¸)')\n",
    "    reg_meFirst = re.compile(r'(æˆ‘|æœ¬äºº|è‡ªå·±)æ˜¯(.*)?(ç¾¯|ç“¶|é­š|ç¾Š|ç‰›|é›™å­|èŸ¹|ç…|è™•å¥³|ç§¤|è |å°„æ‰‹)(.*)?(ä»–|å¥¹|é–ƒ|å‹|ä»»|æ–¹|ç”·|å¥³)æ˜¯(.*)?(ç¾¯|ç“¶|é­š|ç¾Š|ç‰›|é›™å­|èŸ¹|ç…|è™•å¥³|ç§¤|è |å°„æ‰‹)')\n",
    "    reg_heFirst = re.compile(r'(ä»–|å¥¹|é–ƒ|å‹|ä»»|æ–¹|ç”·|å¥³)(.*)?æ˜¯(.*)?(ç¾¯|ç“¶|é­š|ç¾Š|ç‰›|é›™å­|èŸ¹|ç…|è™•å¥³|ç§¤|è |å°„æ‰‹)(.*)?(æˆ‘)æ˜¯(.*)?(ç¾¯|ç“¶|é­š|ç¾Š|ç‰›|é›™å­|èŸ¹|ç…|è™•å¥³|ç§¤|è |å°„æ‰‹)')    \n",
    "    \n",
    "    ans = -1\n",
    "    ans2 = -1\n",
    "    for i in range(len(sep)):\n",
    "        if sep[i][-1]=='çœ·':\n",
    "            continue\n",
    "        output = reg.findall(sep[i])\n",
    "        flag = True\n",
    "        if len(output)!=0:\n",
    "            if len(output[0][1])!=0:\n",
    "                if (output[0][1][-1] in {\"ä¸\",\"çš„\",\"åª\",\"åƒ\",\"é‚„\",\"é€™\"}):\n",
    "                    flag = False\n",
    "                elif output[0][1][-1]==\"éƒ½\":\n",
    "                    if output[0][1][0] not in {\"å€‘\", \"è·Ÿ\", \"å’Œ\", \"èˆ‡\"}:\n",
    "                        flag = False\n",
    "                else:\n",
    "                    if len(set(output[0][1]) & notme)!=0 and output[0][1][-1]!='ä¹Ÿ':\n",
    "                        flag = False  \n",
    "            if len(output[0][2])!=0:\n",
    "                if re.findall(\"é‡\", output[0][2]) != []:\n",
    "                    flag = False\n",
    "                if output[0][2][-1]==\"è·Ÿ\":\n",
    "                    flag = False\n",
    "            if flag == True:\n",
    "                ans = output[0][-1]\n",
    "                #print (sep[i])\n",
    "                continue\n",
    "        \n",
    "        output1 = reg_meFirst.findall(sep[i])\n",
    "        output2 = reg_heFirst.findall(sep[i])        \n",
    "        if len(output1)!=0: \n",
    "            ans = output1[0][2]\n",
    "            ans2 = output1[0][-1]\n",
    "        elif len(output2)!=0:\n",
    "            ans = output2[0][-1] \n",
    "            ans2 = output2[0][3]\n",
    "            \n",
    "    return ans, ans2\n",
    "\n",
    "def classify1_3(data, num_class):    \n",
    "    third = {}\n",
    "    for ID in data:\n",
    "        content = data[ID]['content']\n",
    "        holder = re.split(',|\\?| |\\(|\\)|\\.|~|ï¼Œ|ã€‚|ã€|\\n|ï¼š|ï¼›|ï¼Ÿ|â€¦|â‹¯|ï¼ˆ|ï¼‰|ï¼|ï½',content)\n",
    "        Sep = []\n",
    "        for i in range(len(holder)):\n",
    "            if len(holder[i])>2:\n",
    "                Sep.append(holder[i])\n",
    "        Answer, Answer2 = SenBySen(Sep)\n",
    "        if Answer != -1:\n",
    "            third[str(data[ID]['id'])] = mapping(Answer, num_class)                        \n",
    "    return third\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify1_4(data, num_class):\n",
    "    forth = {}\n",
    "    reg = re.compile\\\n",
    "    (r'(BY|By|by|btw|BTW|Btw|-)(.*)?(æ‘©|é­”|ç¾¯|ç“¶|é­š|ğŸŸ|ğŸ |ç¾Š|ğŸ‘|ç‰›|ğŸ®|ğŸ‚|é›™å­|èŸ¹|ğŸ¦€ï¸|ç…|ğŸ¦ï¸|è™•å¥³|ç§¤|âš–ï¸|è |ğŸ¦‚ï¸|å°„æ‰‹|ğŸ¹ï¸)')\n",
    "    # sign = re.compile(r'(æ‘©|é­”|ç¾¯|ç“¶|é­š|ç¾Š|ç‰›|é›™å­|èŸ¹|ç…|è™•å¥³|ç§¤|è |å°„æ‰‹)')    \n",
    "    for ID in data:\n",
    "        content = data[ID]['content']\n",
    "        holder = re.split(',|\\?| |\\(|\\)|\\.|~|ï¼Œ|ã€‚|ã€|\\n|ï¼š|ï¼›|ï¼Ÿ|â€¦|â‹¯|ï¼ˆ|ï¼‰|ï¼|ï½',content)\n",
    "        sep = []\n",
    "        for i in range(len(holder)):\n",
    "            if len(holder[i])>2:\n",
    "                sep.append(holder[i])\n",
    "\n",
    "        if len(sep)!=0:\n",
    "            output = reg.findall(sep[-1])\n",
    "            flag = True            \n",
    "            if len(output)!=0:\n",
    "                # print (output[0])\n",
    "                ans = output[0][-1]\n",
    "                # print (sep[-1])\n",
    "                # print (str(reg.search(sep[-1]))+str(data[a]['id'])+\" --> \"+ ans+ str(mapping(ans, num_class)))\n",
    "                # forth[str(data[a]['id'])]=[]\n",
    "                # forth[str(data[a]['id'])].append(data[a])\n",
    "                # forth[str(data[a]['id'])].append(mapping(ans, num_class))\n",
    "                forth[str(data[ID]['id'])] = mapping(ans, num_class)\n",
    "    return forth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gather(NCLASS):\n",
    "    way1 = classify1_1(jf, NCLASS)\n",
    "    way2 = classify1_2(jf, NCLASS)\n",
    "    way3 = classify1_3(jf, NCLASS)\n",
    "    way4 = classify1_4(jf, NCLASS)\n",
    "\n",
    "    test = {}\n",
    "    test.update(way1)\n",
    "    test.update(way2)\n",
    "    test.update(way3)\n",
    "    test.update(way4)\n",
    "    return test\n",
    "\n",
    "id_type = Gather(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1831, 1758, 2091, 1797]\n"
     ]
    }
   ],
   "source": [
    "# see how much auther each type\n",
    "fourCounter=[0,0,0,0]\n",
    "for ele in id_type.values():\n",
    "    fourCounter[ele]+=1\n",
    "print (fourCounter)\n",
    "# [2344, 2226, 2715, 2311]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1831, 1758, 2091, 1797, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# see how much auther each horoscope\n",
    "twelveCounter=[0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "for ele in id_type.values():\n",
    "    twelveCounter[ele]+=1\n",
    "print (twelveCounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('four_type0730.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(id_type, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whoTAGwho(data, num_class):\n",
    "    def mainChar(gen, i, u):\n",
    "        if gen=='F':\n",
    "            mtx_f[i][u]+=1\n",
    "        else:\n",
    "            mtx_m[i][u]+=1\n",
    "            \n",
    "    reg_title = re.compile(r'(é­”|æ‘©|ç¾¯|â™‘|ç“¶|â™’|é­š|ğŸŸ|ğŸ |â™“|ç¾Š|ğŸ‘|â™ˆ|ç‰›|ğŸ‚|ğŸ®|â™‰|é›™å­|â™Š|èŸ¹|ğŸ¦€ï¸|â™‹|ç…|ğŸ¦ï¸|â™Œ|è™•å¥³|â™|ç§¤|âš–ï¸|â™|è |ğŸ¦‚ï¸|â™|å°„æ‰‹|ğŸ¹ï¸|â™).*(ç”·|å¥³).*(é­”|æ‘©|ç¾¯|â™‘|ç“¶|â™’|é­š|ğŸŸ|ğŸ |â™“|ç¾Š|ğŸ‘|â™ˆ|ç‰›|ğŸ‚|ğŸ®|â™‰|é›™å­|â™Š|èŸ¹|ğŸ¦€ï¸|â™‹|ç…|ğŸ¦ï¸|â™Œ|è™•å¥³|â™|ç§¤|âš–ï¸|â™|è |ğŸ¦‚ï¸|â™|å°„æ‰‹|ğŸ¹ï¸|â™).*(ç”·|å¥³)')\n",
    "    reg = re.compile(r'(é­”|æ‘©|ç¾¯|â™‘|ç“¶|â™’|é­š|ğŸŸ|ğŸ |â™“|ç¾Š|ğŸ‘|â™ˆ|ç‰›|ğŸ‚|ğŸ®|â™‰|é›™å­|â™Š|èŸ¹|ğŸ¦€ï¸|â™‹|ç…|ğŸ¦ï¸|â™Œ|è™•å¥³|â™|ç§¤|âš–ï¸|â™|è |ğŸ¦‚ï¸|â™|å°„æ‰‹|ğŸ¹ï¸|â™)')\n",
    "    reg_sex = re.compile(r'(ç”·|å¥³)')\n",
    "    reg_tag = re.compile(r'(ç¾¯|ç“¶|é­š|ç¾Š|ç‰›|é›™å­|èŸ¹|ç…|è™•å¥³|ç§¤|è |å°„æ‰‹)')\n",
    "    reg_same1 = re.compile(r'(æˆ‘å€‘|æˆ‘å’Œ|æˆ‘è·Ÿ|å’Œæˆ‘|è·Ÿæˆ‘)(.*)?(éƒ½æ˜¯|éƒ½4|ä¸€æ¨£æ˜¯|åŒä¸€|åŒæ˜Ÿ)(.*)?(æ‘©|ç¾¯|é­”|ç“¶|é­š|ğŸŸ|ğŸ |ç¾Š|ğŸ‘|ç‰›|ğŸ®|ğŸ‚|é›™å­|èŸ¹|ğŸ¦€ï¸|ç…|ğŸ¦ï¸|è™•å¥³|ç§¤|âš–ï¸|è |ğŸ¦‚ï¸|å°„æ‰‹|ğŸ¹ï¸)')\n",
    "    reg_same2 = re.compile(r'æ˜¯(.*)?(ç¾¯ç¾¯é…|ç“¶ç“¶é…|é­šé­šé…|ç¾Šç¾Šé…|ç‰›ç‰›é…|é›™é›™é…|èŸ¹èŸ¹é…|ç…ç…é…|è™•è™•é…|ç§¤ç§¤é…|è è é…|å°„å°„æˆ€|ç¾¯ç¾¯æˆ€|ç“¶ç“¶æˆ€|é­šé­šæˆ€|ç¾Šç¾Šæˆ€|ç‰›ç‰›æˆ€|é›™é›™æˆ€|èŸ¹èŸ¹æˆ€|ç…ç…æˆ€|è™•è™•æˆ€|ç§¤ç§¤æˆ€|è è æˆ€|å°„å°„æˆ€)')\n",
    "    reg_same3 = re.compile(r'(.)åŒæ˜Ÿåº§')\n",
    "    reg_same4 = re.compile(r'(æˆ‘|è‡ªå·±|æœ¬äºº|æœ¬èº«|å¥¹|ä»–|å‹|é–ƒ|å¦ä¸€åŠ|ç¾ä»»|å‰ä»»|çˆ¸|åª½|å“¥|å¼Ÿ|å§Š|å¦¹)(.*)?(ä¹Ÿæ˜¯)(æ‘©|ç¾¯|é­”|ç“¶|æ°´ç“¶|é­š|é›™é­š|ğŸŸ|ğŸ |ç¾Š|ç‰¡ç¾Š|ğŸ‘|ç‰›|é‡‘ç‰›|ğŸ®|ğŸ‚|é›™å­|èŸ¹|ğŸ¦€ï¸|ç…|ğŸ¦ï¸|è™•å¥³|ç§¤|å¤©ç§¤|âš–ï¸|è |å¤©è |ğŸ¦‚ï¸|å°„æ‰‹|ğŸ¹ï¸)')\n",
    "    reg_intro = re.compile(r'(ä»–|å¥¹|é–ƒ|å‹|ä»»|æ–¹|ç”·|å¥³|å®¶)(.*)?æ˜¯(.*)?(æ‘©|é­”|ç¾¯|ç“¶|é­š|ğŸŸ|ğŸ |ç¾Š|ğŸ‘|ç‰›|ğŸ®|ğŸ‚|é›™å­|èŸ¹|ğŸ¦€ï¸|ç…|ğŸ¦ï¸|è™•å¥³|ç§¤|âš–ï¸|è |ğŸ¦‚ï¸|å°„æ‰‹|ğŸ¹ï¸)')\n",
    "    \n",
    "    mtx_m = [[0 for x in range(num_class)] for y in range(num_class)]\n",
    "    mtx_f = [[0 for x in range(num_class)] for y in range(num_class)]\n",
    "    wtw = {}\n",
    "    \n",
    "    for a in range(num_data):\n",
    "        ID = str(data[a]['id'])\n",
    "        gender = data[a]['gender']\n",
    "        \n",
    "        if ID in id_type.keys():\n",
    "        \n",
    "            #judge by title, content, gender \n",
    "            output = set(reg.findall(data[a]['title']))\n",
    "            output = horoNorm1(output)\n",
    "            sex = reg_sex.findall(data[a]['title'])\n",
    "            if len(output)==1 and len(sex)==1:\n",
    "                output = horoNorm2(output)\n",
    "                another = list(output)[0]\n",
    "                if sex[0]=='ç”·' and gender=='F':\n",
    "                    me, you = id_type[ID], mapping(another, num_class)\n",
    "                    mainChar(gender, me, you)  #print(ID, me, \"-->\", you, data[a]['title'])\n",
    "                    wtw[ID] = you\n",
    "                    continue\n",
    "                elif sex[0]=='å¥³' and gender=='M':\n",
    "                    me, you = id_type[ID], mapping(another, num_class)\n",
    "                    mainChar(gender, me, you)  #print(ID, me, \"-->\", you, data[a]['title'])\n",
    "                    wtw[ID] = you\n",
    "                    continue\n",
    "\n",
    "            # judge by title and gender\n",
    "            output = reg_title.findall(data[a]['title'])\n",
    "            if len(output)!=0 and output[0][1]!=output[0][3] : # different gender            \n",
    "                if gender==\"F\":\n",
    "                    ans = output[0][output[0].index(\"å¥³\")-1]\n",
    "                    ref = output[0][output[0].index(\"ç”·\")-1]\n",
    "                else:\n",
    "                    ans = output[0][output[0].index(\"ç”·\")-1]\n",
    "                    ref = output[0][output[0].index(\"å¥³\")-1]\n",
    "                me, you = mapping(ans, num_class), mapping(ref, num_class)\n",
    "                mainChar(gender, me, you)  #print(data[a]['gender'],ans,me,\"-->\",ref,you)\n",
    "                wtw[ID] = you\n",
    "                continue\n",
    "\n",
    "            # judge by title, tag\n",
    "            output = set(reg.findall(data[a]['title']))\n",
    "            output = horoNorm1(output)\n",
    "            if len(output)==1:\n",
    "                output = horoNorm2(output)\n",
    "                another = list(output)\n",
    "                together = \" \".join(data[a]['topics'])\n",
    "                tags = set(reg_tag.findall(together))            \n",
    "                if len(tags)==2:\n",
    "                    sign = tags - set(another)\n",
    "                    ans, ref = list(sign)[0], another[0]\n",
    "                    me, you = mapping(ans, num_class), mapping(ref, num_class)  #print(jf[a]['title'],ans,me,\"-->\",ref,you)\n",
    "                    mainChar(gender, me, you)\n",
    "                    wtw[ID] = you\n",
    "                    continue\n",
    "\n",
    "            \n",
    "            content = data[a]['content']\n",
    "            holder = re.split(',|\\?| |\\(|\\)|\\.|~|ï¼Œ|ã€‚|ã€|\\n|ï¼š|ï¼›|ï¼Ÿ|â€¦|â‹¯|ï¼ˆ|ï¼‰|ï¼|ï½',content)\n",
    "            sep = []\n",
    "            for i in range(len(holder)):\n",
    "                if len(holder[i])>2:\n",
    "                    sep.append(holder[i])\n",
    "                    \n",
    "            ans, ref = SenBySen(sep)\n",
    "            if ans!=-1 and ref!=-1:\n",
    "                me, you = mapping(ans, num_class), mapping(ref, num_class)\n",
    "                mainChar(gender, me, you)\n",
    "                wtw[ID] = you\n",
    "                continue\n",
    "\n",
    "            for i in range(len(sep)):\n",
    "                if len( reg_same1.findall(sep[i]) )!=0:\n",
    "                    output = reg_same1.findall(sep[i])\n",
    "                    ans = output[0][-1]\n",
    "                    we = mapping(ans, num_class)\n",
    "                    mainChar(gender, we, we)\n",
    "                    wtw[ID] = we                  \n",
    "                elif len( reg_same2.findall(sep[i]) )!=0:\n",
    "                    output = reg_same2.findall(sep[i])\n",
    "                    ans = output[0][-1][-2]\n",
    "                    we = mapping(ans, num_class)\n",
    "                    mainChar(gender, we, we)\n",
    "                    wtw[ID] = we\n",
    "                elif len( reg_same3.findall(sep[i]) )!=0:\n",
    "                    output = reg_same3.findall(sep[i])\n",
    "                    if (ID in id_type) and output[0]!='ä¸':\n",
    "                        we = id_type[ID]\n",
    "                        mainChar(gender, we, we)\n",
    "                        wtw[ID] = we\n",
    "                elif len( reg_same4.findall(sep[i]) )!=0:\n",
    "                    output = reg_same4.findall(sep[i])\n",
    "                    output = horoNorm2(output)\n",
    "                    ans = output[0][-1]\n",
    "                    we = mapping(ans, num_class)\n",
    "                    if we == id_type[ID]:\n",
    "                        mainChar(gender, we, we)\n",
    "                        wtw[ID] = we  #print(ID, reg_same4.findall(sep[i]), sep[i])\n",
    "                elif len( reg_intro.findall(sep[i]) )!=0:\n",
    "                    output = reg_intro.findall(sep[i])\n",
    "                    ref = output[0][-1]\n",
    "                    me ,you = id_type[ID], mapping(ref, num_class)\n",
    "                    mainChar(gender, me, you)\n",
    "                    wtw[ID] = you                   \n",
    "    return mtx_m, mtx_f, wtw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# relation: list of list\n",
    "relation_m, relation_f, crush = whoTAGwho(jf, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def makeForm(rM, rF, num_class):    \n",
    "    if num_class==12:\n",
    "        cnameF = ['æ‘©ç¾¯å¥³','æ°´ç“¶å¥³','é›™é­šå¥³','ç‰¡ç¾Šå¥³','é‡‘ç‰›å¥³','é›™å­å¥³','å·¨èŸ¹å¥³','ç…å­å¥³','è™•å¥³å¥³','å¤©ç§¤å¥³','å¤©è å¥³','å°„æ‰‹å¥³']\n",
    "        df = pd.DataFrame(rM, columns = cnameF)\n",
    "        Mmain = df.rename(index={0:'æ‘©ç¾¯ç”·',1:'æ°´ç“¶ç”·',2:'é›™é­šç”·',3:'ç‰¡ç¾Šç”·',4:'é‡‘ç‰›ç”·',5:'é›™å­ç”·',6:'å·¨èŸ¹ç”·',7:'ç…å­ç”·',8:'è™•å¥³ç”·',9:'å¤©ç§¤ç”·',10:'å¤©è ç”·',11:'å°„æ‰‹ç”·'})\n",
    "\n",
    "        cnameM = ['æ‘©ç¾¯ç”·','æ°´ç“¶ç”·','é›™é­šç”·','ç‰¡ç¾Šç”·','é‡‘ç‰›ç”·','é›™å­ç”·','å·¨èŸ¹ç”·','ç…å­ç”·','è™•å¥³ç”·','å¤©ç§¤ç”·','å¤©è ç”·','å°„æ‰‹ç”·']\n",
    "        df2 = pd.DataFrame(rF, columns = cnameM)\n",
    "        Fmain = df2.rename(index={0:'æ‘©ç¾¯å¥³',1:'æ°´ç“¶å¥³',2:'é›™é­šå¥³',3:'ç‰¡ç¾Šå¥³',4:'é‡‘ç‰›å¥³',5:'é›™å­å¥³',6:'å·¨èŸ¹å¥³',7:'ç…å­å¥³',8:'è™•å¥³å¥³',9:'å¤©ç§¤å¥³',10:'å¤©è å¥³',11:'å°„æ‰‹å¥³'})\n",
    "    elif num_class==4:\n",
    "        cnameF = ['åœŸè±¡å¥³','é¢¨è±¡å¥³','æ°´è±¡å¥³','ç«è±¡å¥³']\n",
    "        df = pd.DataFrame(rM, columns = cnameF)\n",
    "        Mmain = df.rename(index={0:'åœŸè±¡ç”·',1:'é¢¨å‘ç”·',2:'æ°´è±¡ç”·',3:'ç«è±¡ç”·'})\n",
    "\n",
    "        cnameM = ['åœŸè±¡ç”·','é¢¨è±¡ç”·','æ°´è±¡ç”·','ç«è±¡ç”·']\n",
    "        df2 = pd.DataFrame(rF, columns = cnameM)\n",
    "        Fmain = df2.rename(index={0:'åœŸè±¡å¥³',1:'é¢¨è±¡å¥³',2:'æ°´è±¡å¥³',3:'ç«è±¡å¥³'})\n",
    "    return Mmain, Fmain\n",
    "\n",
    "MaleMain, FemaleMain = makeForm(relation_m, relation_f, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>åœŸè±¡å¥³</th>\n",
       "      <th>é¢¨è±¡å¥³</th>\n",
       "      <th>æ°´è±¡å¥³</th>\n",
       "      <th>ç«è±¡å¥³</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>åœŸè±¡ç”·</th>\n",
       "      <td>175</td>\n",
       "      <td>89</td>\n",
       "      <td>140</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>é¢¨å‘ç”·</th>\n",
       "      <td>89</td>\n",
       "      <td>114</td>\n",
       "      <td>101</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æ°´è±¡ç”·</th>\n",
       "      <td>128</td>\n",
       "      <td>121</td>\n",
       "      <td>196</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ç«è±¡ç”·</th>\n",
       "      <td>121</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     åœŸè±¡å¥³  é¢¨è±¡å¥³  æ°´è±¡å¥³  ç«è±¡å¥³\n",
       "åœŸè±¡ç”·  175   89  140  106\n",
       "é¢¨å‘ç”·   89  114  101  108\n",
       "æ°´è±¡ç”·  128  121  196  137\n",
       "ç«è±¡ç”·  121  101  100  129"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MaleMain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>åœŸè±¡ç”·</th>\n",
       "      <th>é¢¨è±¡ç”·</th>\n",
       "      <th>æ°´è±¡ç”·</th>\n",
       "      <th>ç«è±¡ç”·</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>åœŸè±¡å¥³</th>\n",
       "      <td>419</td>\n",
       "      <td>284</td>\n",
       "      <td>369</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>é¢¨è±¡å¥³</th>\n",
       "      <td>356</td>\n",
       "      <td>392</td>\n",
       "      <td>328</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æ°´è±¡å¥³</th>\n",
       "      <td>399</td>\n",
       "      <td>334</td>\n",
       "      <td>468</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ç«è±¡å¥³</th>\n",
       "      <td>442</td>\n",
       "      <td>273</td>\n",
       "      <td>320</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     åœŸè±¡ç”·  é¢¨è±¡ç”·  æ°´è±¡ç”·  ç«è±¡ç”·\n",
       "åœŸè±¡å¥³  419  284  369  246\n",
       "é¢¨è±¡å¥³  356  392  328  259\n",
       "æ°´è±¡å¥³  399  334  468  322\n",
       "ç«è±¡å¥³  442  273  320  312"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FemaleMain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9596\n",
      "8252\n"
     ]
    }
   ],
   "source": [
    "print (len(id_type.keys()))\n",
    "print (len(crush))\n",
    "with open('crush0228_4.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(crush, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_data(data, file):\n",
    "\twith open(file, 'wb') as f:\n",
    "\t\tpickle.dump(data, f)\n",
    "        \n",
    "save_data(MaleMain, 'relation_male_4.pickle')\n",
    "save_data(FemaleMain, 'relation_female_4.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ†åäºŒé¡ ï¼ˆå…©å±¤ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "twelve = [{'é­”','æ‘©','ç¾¯','â™‘'},{'ç‰›','ğŸ‚','ğŸ®','â™‰'},{'è™•å¥³','â™'}]\n",
    "fong = [{'ç“¶','â™’'},{'é›™å­','â™Š'},{'ç§¤','âš–ï¸','â™'}]\n",
    "sui = [{'é­š','ğŸŸ','ğŸ ','â™“'},{'èŸ¹','ğŸ¦€ï¸','â™‹'},{'è ','ğŸ¦‚ï¸','â™'}]\n",
    "huo = [{'ç¾Š','ğŸ‘','â™ˆ'},{'ç…','ğŸ¦ï¸','â™Œ'},{'å°„æ‰‹','ğŸ¹ï¸','â™'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping2(char, group):\n",
    "    for i in range(3):\n",
    "        if char in group[i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify2_1(data, name):\n",
    "    first = {}\n",
    "    for a in range(len(data)):    \n",
    "        reg = re.compile(r'(é­”|æ‘©|ç¾¯|â™‘|ç“¶|â™’|é­š|ğŸŸ|ğŸ |â™“|ç¾Š|ğŸ‘|â™ˆ|ç‰›|ğŸ‚|ğŸ®|â™‰|é›™å­|â™Š|èŸ¹|ğŸ¦€ï¸|â™‹|ç…|ğŸ¦ï¸|â™Œ|è™•å¥³|â™|ç§¤|âš–ï¸|â™|è |ğŸ¦‚ï¸|â™|å°„æ‰‹|ğŸ¹ï¸|â™).*(ç”·|å¥³).*(é­”|æ‘©|ç¾¯|â™‘|ç“¶|â™’|é­š|ğŸŸ|ğŸ |â™“|ç¾Š|ğŸ‘|â™ˆ|ç‰›|ğŸ‚|ğŸ®|â™‰|é›™å­|â™Š|èŸ¹|ğŸ¦€ï¸|â™‹|ç…|ğŸ¦ï¸|â™Œ|è™•å¥³|â™|ç§¤|âš–ï¸|â™|è |ğŸ¦‚ï¸|â™|å°„æ‰‹|ğŸ¹ï¸|â™).*(ç”·|å¥³)')\n",
    "        output = reg.findall(data[a]['title'])\n",
    "        if len(output)!=0 and output[0][1]!=output[0][3] : # different gender\n",
    "            if data[a]['gender']==\"F\":\n",
    "                ans = output[0][output[0].index(\"å¥³\")-1]\n",
    "            else:\n",
    "                ans = output[0][output[0].index(\"ç”·\")-1]\n",
    "            first[str(data[a]['id'])]=[]\n",
    "            first[str(data[a]['id'])].append([data[a]['id'], data[a]['title'], data[a]['content'], data[a]['topics']])\n",
    "            start = id_type[str(data[a]['id'])]*3\n",
    "            if mapping2(ans, name)==None:\n",
    "                print (data[a])\n",
    "            first[str(data[a]['id'])].append(mapping2(ans, name))\n",
    "            print (mapping2(ans, name))\n",
    "    return first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify2_2(data, name):\n",
    "    second = {}\n",
    "    reg = re.compile(r'(é­”|æ‘©|ç¾¯|â™‘|ç“¶|â™’|é­š|ğŸŸ|ğŸ |â™“|ç¾Š|ğŸ‘|â™ˆ|ç‰›|ğŸ‚|ğŸ®|â™‰|é›™å­|â™Š|èŸ¹|ğŸ¦€ï¸|â™‹|ç…|ğŸ¦ï¸|â™Œ|è™•å¥³|â™|ç§¤|âš–ï¸|â™|è |ğŸ¦‚ï¸|â™|å°„æ‰‹|ğŸ¹ï¸|â™)')\n",
    "    \n",
    "    for a in range(len(data)):\n",
    "        output = reg.findall(data[a]['title'])\n",
    "        if len(output)==1:\n",
    "            if output[0]=='é­”':\n",
    "                output[0] = 'æ‘©'\n",
    "            together = \" \".join(data[a]['topics'])\n",
    "            another = {1}\n",
    "            another.add(output[0])\n",
    "            tags = set(reg.findall(together))\n",
    "            if len(tags)==2:\n",
    "                sign = tags - another\n",
    "                # print (a, data[a]['title'], tags, \"-\", output[0], \"-->\", end=\" \")\n",
    "                ans = list(sign)[0]\n",
    "                # print (ans, mapping2(ans, name))\n",
    "                second[str(data[a]['id'])]=[]\n",
    "                second[str(data[a]['id'])].append([data[a]['id'], data[a]['title'], data[a]['content'], data[a]['topics']])\n",
    "                start = id_type[str(data[a]['id'])]*3\n",
    "                if mapping2(ans, name)==None:\n",
    "                        print (data[a])\n",
    "                second[str(data[a]['id'])].append(mapping2(ans, name))\n",
    "    return second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify2_3(data, name):\n",
    "    third = {}\n",
    "    notme = {\"å¦\",\"å‹\",\"ä»»\",\"é–ƒ\",\"åª½\",\"çˆ¸\",\"å“¥\",\"å§Š\",\"å¼Ÿ\",\"å¦¹\",\"å…¬\",\"å©†\",\"å¥¹\",\"ä»–\",\"å®¶\",\"æœ\",\"é‡\"}\n",
    "    reg = re.compile\\\n",
    "    (r'(æˆ‘|æœ¬äºº|æœ¬èº«|å°å¼Ÿ|å°å¦¹|å°å¥³å­|åŸpo|åœ¨ä¸‹|å¶)(.*)?æ˜¯(.*)?(æ‘©|é­”|ç¾¯|ç“¶|é­š|ğŸŸ|ğŸ |ç¾Š|ğŸ‘|ç‰›|ğŸ®|ğŸ‚|é›™å­|èŸ¹|ğŸ¦€ï¸|ç…|ğŸ¦ï¸|è™•å¥³|ç§¤|âš–ï¸|è |ğŸ¦‚ï¸|å°„æ‰‹|ğŸ¹ï¸)')\n",
    "    # sign = re.compile(r'(æ‘©|é­”|ç¾¯|ç“¶|é­š|ç¾Š|ç‰›|é›™å­|èŸ¹|ç…|è™•å¥³|ç§¤|è |å°„æ‰‹)')    \n",
    "    for a in range(len(data)):\n",
    "        content = data[a]['content']\n",
    "        holder = re.split(',|\\?| |\\(|\\)|\\.|~|ï¼Œ|ã€‚|ã€|\\n|ï¼š|ï¼›|ï¼Ÿ|â€¦|â‹¯|ï¼ˆ|ï¼‰|ï¼|ï½',content)\n",
    "        sep = []\n",
    "        for i in range(len(holder)):\n",
    "            if len(holder[i])>2:\n",
    "                sep.append(holder[i])\n",
    "\n",
    "        for i in range(len(sep)):\n",
    "            output = reg.findall(sep[i])\n",
    "            flag = True\n",
    "            if sep[i][-1]=='çœ·':\n",
    "                continue\n",
    "            if len(output)!=0:\n",
    "                if len(output[0][1])!=0:\n",
    "                    if output[0][1][-1] in {\"ä¸\",\"çš„\",\"åª\",\"åƒ\",\"é‚„\",\"é€™\"}:\n",
    "                        flag = False\n",
    "                    elif output[0][1][-1]==\"éƒ½\":\n",
    "                        if output[0][1][0] not in {\"å€‘\", \"è·Ÿ\", \"å’Œ\", \"èˆ‡\"}:\n",
    "                            flag = False\n",
    "                    else:\n",
    "                        if len(set(output[0][1]) & notme)!=0:\n",
    "                            flag = False  \n",
    "\n",
    "                if len(output[0][2])!=0:\n",
    "                    if re.findall(\"é‡\", output[0][2]) != []:\n",
    "                        flag = False\n",
    "                    if output[0][2][-1]==\"è·Ÿ\":\n",
    "                        flag = False\n",
    "                if flag == True:\n",
    "                    ans = output[0][-1]\n",
    "                    # print (str(reg.search(sep[i]))+str(data[a]['id'])+\" --> \"+ ans+ str(mapping2(ans, name)))\n",
    "                    third[str(data[a]['id'])]=[]\n",
    "                    third[str(data[a]['id'])].append([data[a]['id'], data[a]['title'], data[a]['content'], data[a]['topics']])\n",
    "                    start = id_type[str(data[a]['id'])]*3\n",
    "                    if mapping2(ans, name)==None:\n",
    "                        print (data[a])\n",
    "                    third[str(data[a]['id'])].append(mapping2(ans, name))\n",
    "    return third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix3way(ds, kind):\n",
    "    a1 = classify2_1(ds, kind)\n",
    "    a2 = classify2_2(ds, kind)\n",
    "    a3 = classify2_3(ds, kind)\n",
    "    empty = {}\n",
    "    empty.update(a1)\n",
    "    empty.update(a2)\n",
    "    empty.update(a3)\n",
    "    ids = list(empty.keys())\n",
    "    counter = [0,0,0]\n",
    "    for ID in ids:\n",
    "        counter[empty[ID][1]]+=1\n",
    "    print (counter)\n",
    "    \n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typen['id'] = [datas, num]\n",
    "type1 = mix3way(earth, tu)\n",
    "type2 = mix3way(wind, fong)\n",
    "type3 = mix3way(water, sui)\n",
    "type4 = mix3way(fire, huo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[403, 500, 640]\n",
      "[508, 484, 536]\n",
      "[576, 634, 697]\n",
      "[517, 571, 514]\n"
     ]
    }
   ],
   "source": [
    "id_type12 = mix4type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6580\n"
     ]
    }
   ],
   "source": [
    "print(len(list(id_type12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
