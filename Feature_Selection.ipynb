{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# increase accuracy: \n",
    "## 1. Finding the most optimal C and gamma using grid search.\n",
    "## 2. Finding the most discriminative feature using F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1899, 1231)\n",
      "(5564, 1231)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_M = pd.read_csv('ReadyM1000_200_0228.csv')\n",
    "df_F = pd.read_csv('ReadyF1000_200_0228.csv')\n",
    "\n",
    "df1_M = df_M.iloc[:,1:]\n",
    "df1_F = df_F.iloc[:,1:]\n",
    "print (df1_M.shape)\n",
    "print (df1_F.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>w2v_key_0</th>\n",
       "      <th>w2v_key_1</th>\n",
       "      <th>w2v_key_2</th>\n",
       "      <th>w2v_key_3</th>\n",
       "      <th>w2v_key_4</th>\n",
       "      <th>w2v_key_5</th>\n",
       "      <th>w2v_key_6</th>\n",
       "      <th>w2v_key_7</th>\n",
       "      <th>w2v_key_8</th>\n",
       "      <th>...</th>\n",
       "      <th>question</th>\n",
       "      <th>exclaim</th>\n",
       "      <th>bracket</th>\n",
       "      <th>ano_1</th>\n",
       "      <th>ano_2</th>\n",
       "      <th>ano_3</th>\n",
       "      <th>crush_1</th>\n",
       "      <th>crush_2</th>\n",
       "      <th>crush_3</th>\n",
       "      <th>crush_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.003865</td>\n",
       "      <td>0.016236</td>\n",
       "      <td>0.016059</td>\n",
       "      <td>-0.023997</td>\n",
       "      <td>-0.021516</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>-0.003001</td>\n",
       "      <td>-0.007643</td>\n",
       "      <td>-0.021347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004274</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.007306</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.016379</td>\n",
       "      <td>-0.028848</td>\n",
       "      <td>-0.026123</td>\n",
       "      <td>0.016086</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.012566</td>\n",
       "      <td>-0.013684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013174</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.014738</td>\n",
       "      <td>0.031344</td>\n",
       "      <td>-0.006113</td>\n",
       "      <td>-0.014888</td>\n",
       "      <td>-0.004157</td>\n",
       "      <td>0.011216</td>\n",
       "      <td>0.039134</td>\n",
       "      <td>-0.022351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>0.011181</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>0.031031</td>\n",
       "      <td>0.050523</td>\n",
       "      <td>-0.052399</td>\n",
       "      <td>-0.057591</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>-0.008779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.027435</td>\n",
       "      <td>-0.073629</td>\n",
       "      <td>0.118453</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>-0.063554</td>\n",
       "      <td>0.067057</td>\n",
       "      <td>-0.090824</td>\n",
       "      <td>0.027772</td>\n",
       "      <td>-0.025290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>2</td>\n",
       "      <td>0.023923</td>\n",
       "      <td>0.026582</td>\n",
       "      <td>0.170401</td>\n",
       "      <td>-0.009743</td>\n",
       "      <td>-0.082327</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>-0.019593</td>\n",
       "      <td>0.157125</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0.069446</td>\n",
       "      <td>-0.006886</td>\n",
       "      <td>0.022364</td>\n",
       "      <td>-0.051795</td>\n",
       "      <td>-0.052784</td>\n",
       "      <td>0.053161</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>0.015815</td>\n",
       "      <td>-0.050410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>1</td>\n",
       "      <td>0.014826</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.015140</td>\n",
       "      <td>-0.046354</td>\n",
       "      <td>-0.024835</td>\n",
       "      <td>0.029137</td>\n",
       "      <td>-0.017067</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>-0.005389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0.023154</td>\n",
       "      <td>-0.040111</td>\n",
       "      <td>0.043670</td>\n",
       "      <td>-0.043374</td>\n",
       "      <td>-0.039188</td>\n",
       "      <td>-0.027308</td>\n",
       "      <td>-0.025167</td>\n",
       "      <td>0.021847</td>\n",
       "      <td>-0.098177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>2</td>\n",
       "      <td>0.023227</td>\n",
       "      <td>0.008353</td>\n",
       "      <td>0.089809</td>\n",
       "      <td>-0.045246</td>\n",
       "      <td>-0.048812</td>\n",
       "      <td>0.031619</td>\n",
       "      <td>0.027890</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.031374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5571 rows × 934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  w2v_key_0  w2v_key_1  w2v_key_2  w2v_key_3  w2v_key_4  w2v_key_5  \\\n",
       "0         2  -0.003865   0.016236   0.016059  -0.023997  -0.021516   0.007525   \n",
       "1         0  -0.007306   0.011842   0.016379  -0.028848  -0.026123   0.016086   \n",
       "2         0   0.002200   0.014738   0.031344  -0.006113  -0.014888  -0.004157   \n",
       "3         3  -0.000416   0.031031   0.050523  -0.052399  -0.057591  -0.000194   \n",
       "4         1  -0.027435  -0.073629   0.118453   0.000135  -0.063554   0.067057   \n",
       "...     ...        ...        ...        ...        ...        ...        ...   \n",
       "5566      2   0.023923   0.026582   0.170401  -0.009743  -0.082327   0.000638   \n",
       "5567      0   0.069446  -0.006886   0.022364  -0.051795  -0.052784   0.053161   \n",
       "5568      1   0.014826   0.002926   0.015140  -0.046354  -0.024835   0.029137   \n",
       "5569      0   0.023154  -0.040111   0.043670  -0.043374  -0.039188  -0.027308   \n",
       "5570      2   0.023227   0.008353   0.089809  -0.045246  -0.048812   0.031619   \n",
       "\n",
       "      w2v_key_6  w2v_key_7  w2v_key_8  ...  question   exclaim   bracket  \\\n",
       "0     -0.003001  -0.007643  -0.021347  ...  0.000000  0.000000  0.004274   \n",
       "1      0.008825   0.012566  -0.013684  ...  0.000000  0.000000  0.013174   \n",
       "2      0.011216   0.039134  -0.022351  ...  0.004861  0.011181  0.006320   \n",
       "3      0.031857   0.002040  -0.008779  ...  0.000000  0.000000  0.000000   \n",
       "4     -0.090824   0.027772  -0.025290  ...  0.009901  0.000000  0.000000   \n",
       "...         ...        ...        ...  ...       ...       ...       ...   \n",
       "5566  -0.019593   0.157125   0.001352  ...  0.023148  0.004630  0.004630   \n",
       "5567   0.008254   0.015815  -0.050410  ...  0.000000  0.000000  0.004831   \n",
       "5568  -0.017067   0.004784  -0.005389  ...  0.007042  0.000000  0.009390   \n",
       "5569  -0.025167   0.021847  -0.098177  ...  0.009434  0.000000  0.009434   \n",
       "5570   0.027890   0.025996   0.031374  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "      ano_1  ano_2  ano_3  crush_1  crush_2  crush_3  crush_4  \n",
       "0         1      1      0        0        1        0        0  \n",
       "1         1      1      0        0        0        1        0  \n",
       "2         1      1      0        0        0        1        0  \n",
       "3         1      1      0        0        1        0        0  \n",
       "4         1      1      0        0        0        1        0  \n",
       "...     ...    ...    ...      ...      ...      ...      ...  \n",
       "5566      0      1      1        0        1        0        0  \n",
       "5567      0      1      0        0        0        1        0  \n",
       "5568      0      1      0        0        0        0        0  \n",
       "5569      1      1      0        0        0        0        1  \n",
       "5570      1      1      0        0        0        1        0  \n",
       "\n",
       "[5571 rows x 934 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833\n",
      "(5571, 833) (5571, 125)\n",
      "X_train: (3899, 125)\n",
      "KKK=15 , Accuracy = 0.2958201785687299\n",
      "\n",
      "(5571, 833) (5571, 167)\n",
      "X_train: (3899, 167)\n",
      "KKK=20 , Accuracy = 0.29079630355464\n",
      "\n",
      "(5571, 833) (5571, 208)\n",
      "X_train: (3899, 208)\n",
      "KKK=25 , Accuracy = 0.29240968549794444\n",
      "\n",
      "(5571, 833) (5571, 250)\n",
      "X_train: (3899, 250)\n",
      "KKK=30 , Accuracy = 0.293310093768841\n",
      "\n",
      "(5571, 833) (5571, 292)\n",
      "X_train: (3899, 292)\n",
      "KKK=35 , Accuracy = 0.2952868994218726\n",
      "\n",
      "(5571, 833) (5571, 333)\n",
      "X_train: (3899, 333)\n",
      "KKK=40 , Accuracy = 0.2943901991646592\n",
      "\n",
      "(5571, 833) (5571, 375)\n",
      "X_train: (3899, 375)\n",
      "KKK=45 , Accuracy = 0.29654185929100757\n",
      "\n",
      "(5571, 833) (5571, 416)\n",
      "X_train: (3899, 416)\n",
      "KKK=50 , Accuracy = 0.29366851671102584\n",
      "\n",
      "(5571, 833) (5571, 458)\n",
      "X_train: (3899, 458)\n",
      "KKK=55 , Accuracy = 0.2945647330535574\n",
      "\n",
      "(5571, 833) (5571, 500)\n",
      "X_train: (3899, 500)\n",
      "KKK=60 , Accuracy = 0.29169622704907283\n",
      "\n",
      "(5571, 833) (5571, 541)\n",
      "X_train: (3899, 541)\n",
      "KKK=65 , Accuracy = 0.29062079837366694\n",
      "\n",
      "(5571, 833) (5571, 583)\n",
      "X_train: (3899, 583)\n",
      "KKK=70 , Accuracy = 0.2900842916588634\n",
      "\n",
      "(5571, 833) (5571, 624)\n",
      "X_train: (3899, 624)\n",
      "KKK=75 , Accuracy = 0.2908014572596363\n",
      "\n",
      "(5571, 833) (5571, 666)\n",
      "X_train: (3899, 666)\n",
      "KKK=80 , Accuracy = 0.2915187853210986\n",
      "\n",
      "(5571, 833) (5571, 708)\n",
      "X_train: (3899, 708)\n",
      "KKK=85 , Accuracy = 0.29169847810594335\n",
      "\n",
      "F_w2v_tfidf_800: max_kkk=45, max_acc=0.29654185929100757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score # 看clf效果好不好\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "df_M = pd.read_csv('ReadyM_w2v_0730.csv')\n",
    "df1_M = df_M.iloc[:,1:]\n",
    "cname = list(df1_M.columns)[1:]\n",
    "\n",
    "# df_F = pd.read_csv('ReadyF_w2v_0730.csv')\n",
    "# df1_F = df_F.iloc[:,1:]\n",
    "# cname = list(df1_F.columns)[1:]\n",
    "\n",
    "print (len(cname))\n",
    "\n",
    "def Scaler(data):\n",
    "    X = data[cname]\n",
    "    y = data[['label']]\n",
    "    # sc = StandardScaler()\n",
    "    sc = MinMaxScaler()\n",
    "    sc.fit(X)\n",
    "    X = sc.transform(X)\n",
    "    return X, y\n",
    "\n",
    "# Univariate feature selection with F-test for feature scoring\n",
    "def FeatureSelection(x, Y, k):\n",
    "    Y = Y.values.ravel()\n",
    "    selector = SelectPercentile(chi2, percentile=k).fit_transform(x, Y)    \n",
    "    print (x.shape, selector.shape)\n",
    "    return selector\n",
    "    \n",
    "def TrainTest(Data, percent):\n",
    "    X, y = Scaler(Data)\n",
    "    X_new = FeatureSelection(X, y, percent)\n",
    "    y = y.values.ravel()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    print ('X_train:', X_train.shape)\n",
    "    clf = SVC(gamma='scale')\n",
    "#     clf = SVC(C=8, cache_size=200, class_weight=None, coef0=0.0,\n",
    "#     decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',\n",
    "#     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "#     tol=0.001, verbose=False)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = cross_val_score(clf, X_new, y, cv=5, scoring='accuracy')\n",
    "    cv_Acc = sum(result)/5.0\n",
    "    \n",
    "    y_p = clf.predict(X_test)\n",
    "    y_t = y_test \n",
    "       \n",
    "    return y_p, y_t, cv_Acc\n",
    "\n",
    "\n",
    "max_kkk, max_acc = 0, 0\n",
    "kkk = np.arange(15,90,5)\n",
    "for k in kkk:\n",
    "    y_pred, y_true, cv_Accuracy = TrainTest(df1_F, k)\n",
    "    print ('KKK={}'.format(k), ', Accuracy =', cv_Accuracy)\n",
    "    \n",
    "    if cv_Accuracy > max_acc:\n",
    "        max_acc = cv_Accuracy\n",
    "        max_kkk = k    \n",
    "    print ()\n",
    "    \n",
    "print ('F_w2v_tfidf_{}: max_kkk={}, max_acc={}'.format(800, max_kkk, max_acc))\n",
    "print ()\n",
    "# confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "# print(confusion_matrix)\n",
    "# classification_report = classification_report(y_true, y_pred, output_dict = False)\n",
    "# print(classification_report)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勝出的比率\n",
    "F_w2v_tfidf_250:  KKK=55 , Accuracy = 0.293665726946899\n",
    "M_w2v_tfidf_250:  KKK=85 , Accuracy = 0.32650024538243455\n",
    "F_w2v_tfidf_500: max_kkk=55, max_acc=0.2951053841399678    \n",
    "M_w2v_tfidf_500: max_kkk=80, max_acc=0.32494352484436734\n",
    "M_w2v_tfidf_800: max_kkk=20, max_acc=0.32719005191862727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label        False\n",
      "w2v_key_0    False\n",
      "w2v_key_1    False\n",
      "w2v_key_2    False\n",
      "w2v_key_3    False\n",
      "             ...  \n",
      "ano_3        False\n",
      "crush_1      False\n",
      "crush_2      False\n",
      "crush_3      False\n",
      "crush_4      False\n",
      "Length: 934, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "check = np.isnan(df1_F).any()\n",
    "print (check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "male\n",
    "17.5: 0.4017\n",
    "    clf = SVC(C=4, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.0625, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "    \n",
    "20: 0.4064 (17.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "female: \n",
    "SVC(C=512, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.000244140625, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "20: 0.3323\n",
    "25: 0.3360\n",
    "28: 0.3369\n",
    "29: 0.3427, 0.3486\n",
    "30: 0.3412, 0.3497\n",
    "31: 0.3425, 0.3475\n",
    "35: 0.3400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "male: \n",
    "18: 0.3975\n",
    "19: 0.3826\n",
    "20: 0.3855\n",
    "21: 0.3855\n",
    "22: 0.3836\n",
    "30: 0.3697"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "female:\n",
    "19: \n",
    "20: 0.3362\n",
    "30: 0.3431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "male: <br>\n",
    "p=21,  cv_acc=0.416469983025764<br>\n",
    "  <br> \n",
    "female: <br>\n",
    "p=26,  cv_acc=0.34938826480722224<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "male: (700, 750, 800, 850)\n",
    "15: 0.3759, 0.3845, \n",
    "18:         0.3879, 0.3922\n",
    "19: 0.3802, 0.3874, 0.3917\n",
    "20: 0.3817, 0.3836, 0.3980, 0.3855\n",
    "21: 0.3759,       , 0.3846\n",
    "22: 0.3702, \n",
    "25: 0.3625,       , 0.3841, 0.3908\n",
    "27:               , 0.3802, 0.3941\n",
    "29:               , 0.3898, 0.3970\n",
    "30: 0.3582, 0.3654, 0.3984, 0.3932\n",
    "31:               , 0.3903\n",
    "35:               , 0.3841\n",
    "50: 0.3429, 0.3481, \n",
    "--> 800, 20, 0.3980\n",
    "\n",
    "female: \n",
    "25: 0.3389                , 0.3495\n",
    "26: 0.3420\n",
    "28: 0.3442\n",
    "30: 0.3458, 0.3445, 0.3506, 0.3503\n",
    "31: 0.3487, 0.3490, 0.3485, 0.3512\n",
    "32: 0.3487, 0.3474, 0.3506, 0.3539\n",
    "33: 0.3402                , 0.3538\n",
    "35: 0.3423, 0.3464, 0.3404, 0.3491\n",
    "40: 0.3400\n",
    "100: 0.27\n",
    "--> 850, 32, 0.3539"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "male:(200, 300)\n",
    "20: 0.3936, 0.3869\n",
    "25: 0.3936, \n",
    "28: 0.3893, \n",
    "29: 0.4008, 0.3888\n",
    "30: 0.4003, \n",
    "31: 0.3960, \n",
    "35: 0.3932, 0.3903\n",
    "--> 800, 200, 29\n",
    "    \n",
    "    \n",
    "female:\n",
    "19: 0.3480\n",
    "20: 0.3573\n",
    "21: 0.3499\n",
    "25: 0.3515\n",
    "30: 0.3549\n",
    "32: 0.3571\n",
    "--> 850, 200, 32\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "發現：用CKIP斷詞，每個維度的貢獻程度較接近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5593, 794)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_M = pd.read_csv('ReadyM800_200_0225.csv')\n",
    "df_F = pd.read_csv('ReadyF850_200_0225.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2088, 1026) (2088, 185)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-292-68c43ea355d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m print(\"The best parameters are %s with a score of %f\"\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load and prepare data set\n",
    "#\n",
    "# dataset for grid search\n",
    "\n",
    "# iris = load_iris()\n",
    "# X = iris.data\n",
    "# y = iris.target\n",
    "\n",
    "# Dataset for decision function visualization: we only keep the first two\n",
    "# features in X and sub-sample the dataset to keep only 2 classes and\n",
    "# make it a binary classification problem.\n",
    "\n",
    "# X_2d = X[:, :2]\n",
    "# X_2d = X_2d[y > 0]\n",
    "# y_2d = y[y > 0]\n",
    "# y_2d -= 1\n",
    "\n",
    "# It is usually a good idea to scale the data for SVM training.\n",
    "# We are cheating a bit in this example in scaling all of the data,\n",
    "# instead of fitting the transformation on the training set and\n",
    "# just applying it on the test set.\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# X_2d = scaler.fit_transform(X_2d)\n",
    "\n",
    "# #############################################################################\n",
    "# Train classifiers\n",
    "#\n",
    "# For an initial search, a logarithmic grid with basis\n",
    "# 10 is often helpful. Using a basis of 2, a finer\n",
    "# tuning can be achieved but at a much higher cost.\n",
    "\n",
    "\n",
    "X, y = Scaler(df1_M)\n",
    "X_new = FeatureSelection(X, y, 18)\n",
    "y = y.values.ravel()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "C_range = [2**-2, 2**-1, 2**0, 2**1, 2**2, 2**3, 2**4, 2**5, 2**6, 2**7, 2**8]\n",
    "gamma_range = [2**-13, 2**-12, 2**-11, 2**-10, 2**-19, 2**-8, 2**-7, 2**-6, 2**-5, 2**-4]\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 女生 grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1899, 283) (1899, 85)\n",
      "Best parameters set found on development set:\n",
      "\n",
      "0.32724719101123595 {'C': 1, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.3034 for {'C': 1, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 1, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 1, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 1, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 1, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 1, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 1, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3062 for {'C': 1, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3244 for {'C': 1, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3272 for {'C': 1, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3265 for {'C': 1, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3020 for {'C': 1, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 2, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 2, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 2, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 2, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 2, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 2, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3041 for {'C': 2, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3244 for {'C': 2, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3237 for {'C': 2, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3265 for {'C': 2, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3125 for {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2956 for {'C': 2, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 4, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 4, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 4, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 4, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 4, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3055 for {'C': 4, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3244 for {'C': 4, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3251 for {'C': 4, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3237 for {'C': 4, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3195 for {'C': 4, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3006 for {'C': 4, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3020 for {'C': 4, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 8, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 8, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 8, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 8, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 8, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3251 for {'C': 8, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3244 for {'C': 8, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3223 for {'C': 8, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3209 for {'C': 8, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.2971 for {'C': 8, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3006 for {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2879 for {'C': 8, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 16, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 16, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 16, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3055 for {'C': 16, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 16, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3244 for {'C': 16, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3223 for {'C': 16, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3153 for {'C': 16, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3062 for {'C': 16, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3041 for {'C': 16, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.2942 for {'C': 16, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2760 for {'C': 16, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 32, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 32, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3055 for {'C': 32, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3251 for {'C': 32, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 32, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3223 for {'C': 32, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3237 for {'C': 32, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3181 for {'C': 32, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3048 for {'C': 32, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3041 for {'C': 32, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.2907 for {'C': 32, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2760 for {'C': 32, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 64, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3055 for {'C': 64, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3251 for {'C': 64, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3230 for {'C': 64, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 64, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3230 for {'C': 64, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3209 for {'C': 64, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.2956 for {'C': 64, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3020 for {'C': 64, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3013 for {'C': 64, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.2865 for {'C': 64, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2760 for {'C': 64, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3055 for {'C': 128, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3251 for {'C': 128, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3230 for {'C': 128, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3202 for {'C': 128, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 128, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3146 for {'C': 128, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 128, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.2992 for {'C': 128, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3083 for {'C': 128, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.2942 for {'C': 128, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.2844 for {'C': 128, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2795 for {'C': 128, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3251 for {'C': 256, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3230 for {'C': 256, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3202 for {'C': 256, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3223 for {'C': 256, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 256, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3083 for {'C': 256, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3020 for {'C': 256, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3202 for {'C': 256, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3048 for {'C': 256, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.2781 for {'C': 256, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.2683 for {'C': 256, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2774 for {'C': 256, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3230 for {'C': 512, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3195 for {'C': 512, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3209 for {'C': 512, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3195 for {'C': 512, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 512, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3069 for {'C': 512, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3069 for {'C': 512, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 512, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.2992 for {'C': 512, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.2816 for {'C': 512, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.2760 for {'C': 512, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2774 for {'C': 512, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3188 for {'C': 1024, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3202 for {'C': 1024, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3209 for {'C': 1024, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3090 for {'C': 1024, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 1024, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3048 for {'C': 1024, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3097 for {'C': 1024, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3013 for {'C': 1024, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.2837 for {'C': 1024, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.2746 for {'C': 1024, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.2711 for {'C': 1024, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2774 for {'C': 1024, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3202 for {'C': 2048, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3209 for {'C': 2048, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3139 for {'C': 2048, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3230 for {'C': 2048, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 2048, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3020 for {'C': 2048, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.2992 for {'C': 2048, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.2914 for {'C': 2048, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.2872 for {'C': 2048, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.2746 for {'C': 2048, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.2711 for {'C': 2048, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2774 for {'C': 2048, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3216 for {'C': 4096, 'gamma': 0.0001220703125, 'kernel': 'rbf'}\n",
      "0.3146 for {'C': 4096, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3195 for {'C': 4096, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3146 for {'C': 4096, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3034 for {'C': 4096, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3027 for {'C': 4096, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.2992 for {'C': 4096, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.2809 for {'C': 4096, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.2718 for {'C': 4096, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.2767 for {'C': 4096, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.2711 for {'C': 4096, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.2774 for {'C': 4096, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "[[ 36  10  66   1]\n",
      " [ 20  10  70   1]\n",
      " [ 26  15 108   0]\n",
      " [ 22  14  74   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.32      0.33       113\n",
      "           1       0.20      0.10      0.13       101\n",
      "           2       0.34      0.72      0.46       149\n",
      "           3       0.50      0.02      0.03       112\n",
      "\n",
      "    accuracy                           0.33       475\n",
      "   macro avg       0.35      0.29      0.24       475\n",
      "weighted avg       0.35      0.33      0.26       475\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "X, y = Scaler(df1_F)\n",
    "X_new = FeatureSelection(X, y, 30)\n",
    "y = y.values.ravel()\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "# tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],'C': [1, 2, 10, 100, 1000]}]\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                     'gamma': [2**-13, 2**-12, 2**-11, 2**-10, 2**-19, 2**-8, 2**-7, 2**-6, 2**-5, 2**-4, 2**-3, 2**-2],\n",
    "                     'C': [2**0, 2**1, 2**2, 2**3, 2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10, 2**11, 2**12]}]\n",
    "\n",
    "# scores = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "# print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "# print()\n",
    "# clf = GridSearchCV(SVC(), tuned_parameters, scoring='%s_macro'%score, cv=5)\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, scoring='accuracy', cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_score_, clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.4f for %r\" % (mean, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(confusion_matrix)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=8, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.03125, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.32935393258426965 {'C': 8, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 男生 grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1899, 1230) (1899, 246)\n",
      "Best parameters set found on development set:\n",
      "\n",
      "0.3965387509405568 {'C': 16, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.25, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3175 for {'C': 0.5, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3266 for {'C': 0.5, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3348 for {'C': 0.5, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3168 for {'C': 0.5, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 0.5, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 1, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 1, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 1, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 1, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 1, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 1, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3190 for {'C': 1, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3439 for {'C': 1, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3815 for {'C': 1, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3868 for {'C': 1, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3695 for {'C': 1, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3273 for {'C': 1, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 1, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 1, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 2, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 2, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 2, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 2, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 2, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3273 for {'C': 2, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3649 for {'C': 2, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3883 for {'C': 2, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3943 for {'C': 2, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3950 for {'C': 2, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3747 for {'C': 2, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3356 for {'C': 2, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 2, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 2, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 2, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 4, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 4, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 4, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 4, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3273 for {'C': 4, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3702 for {'C': 4, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3898 for {'C': 4, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3928 for {'C': 4, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3853 for {'C': 4, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3830 for {'C': 4, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3740 for {'C': 4, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3356 for {'C': 4, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 4, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 4, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 4, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 8, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 8, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 8, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 8, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3755 for {'C': 8, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3905 for {'C': 8, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3913 for {'C': 8, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3807 for {'C': 8, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3868 for {'C': 8, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3815 for {'C': 8, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3740 for {'C': 8, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3356 for {'C': 8, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 8, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 8, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 8, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 16, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 16, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3273 for {'C': 16, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 16, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3965 for {'C': 16, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3868 for {'C': 16, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3785 for {'C': 16, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3845 for {'C': 16, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3755 for {'C': 16, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3815 for {'C': 16, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3740 for {'C': 16, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3356 for {'C': 16, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 16, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 16, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 16, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 32, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3281 for {'C': 32, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3777 for {'C': 32, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 32, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3815 for {'C': 32, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3770 for {'C': 32, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3732 for {'C': 32, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3672 for {'C': 32, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3762 for {'C': 32, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3815 for {'C': 32, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3740 for {'C': 32, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3356 for {'C': 32, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 32, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 32, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 32, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3273 for {'C': 64, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3785 for {'C': 64, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3943 for {'C': 64, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 64, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3740 for {'C': 64, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3695 for {'C': 64, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3634 for {'C': 64, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3574 for {'C': 64, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3762 for {'C': 64, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3815 for {'C': 64, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3740 for {'C': 64, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3356 for {'C': 64, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 64, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 64, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 64, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3792 for {'C': 128, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3950 for {'C': 128, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3770 for {'C': 128, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 128, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3642 for {'C': 128, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3695 for {'C': 128, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3536 for {'C': 128, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3589 for {'C': 128, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3762 for {'C': 128, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3815 for {'C': 128, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3740 for {'C': 128, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3356 for {'C': 128, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 128, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 128, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 128, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3958 for {'C': 256, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3770 for {'C': 256, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3672 for {'C': 256, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 256, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3589 for {'C': 256, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3597 for {'C': 256, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3476 for {'C': 256, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3589 for {'C': 256, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3762 for {'C': 256, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3815 for {'C': 256, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3740 for {'C': 256, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3356 for {'C': 256, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 256, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 256, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 256, 'gamma': 4, 'kernel': 'rbf'}\n",
      "0.3770 for {'C': 512, 'gamma': 0.000244140625, 'kernel': 'rbf'}\n",
      "0.3679 for {'C': 512, 'gamma': 0.00048828125, 'kernel': 'rbf'}\n",
      "0.3634 for {'C': 512, 'gamma': 0.0009765625, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 512, 'gamma': 1.9073486328125e-06, 'kernel': 'rbf'}\n",
      "0.3619 for {'C': 512, 'gamma': 0.00390625, 'kernel': 'rbf'}\n",
      "0.3476 for {'C': 512, 'gamma': 0.0078125, 'kernel': 'rbf'}\n",
      "0.3484 for {'C': 512, 'gamma': 0.015625, 'kernel': 'rbf'}\n",
      "0.3589 for {'C': 512, 'gamma': 0.03125, 'kernel': 'rbf'}\n",
      "0.3762 for {'C': 512, 'gamma': 0.0625, 'kernel': 'rbf'}\n",
      "0.3815 for {'C': 512, 'gamma': 0.125, 'kernel': 'rbf'}\n",
      "0.3740 for {'C': 512, 'gamma': 0.25, 'kernel': 'rbf'}\n",
      "0.3356 for {'C': 512, 'gamma': 0.5, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 512, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 512, 'gamma': 2, 'kernel': 'rbf'}\n",
      "0.3145 for {'C': 512, 'gamma': 4, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60 22 53 14]\n",
      " [24 28 50 10]\n",
      " [36 16 98 13]\n",
      " [30 18 58 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40       149\n",
      "           1       0.33      0.25      0.29       112\n",
      "           2       0.38      0.60      0.46       163\n",
      "           3       0.52      0.27      0.36       146\n",
      "\n",
      "    accuracy                           0.40       570\n",
      "   macro avg       0.41      0.38      0.38       570\n",
      "weighted avg       0.41      0.40      0.39       570\n",
      "\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "X, y = Scaler(df1_M)\n",
    "X_new = FeatureSelection(X, y, 20)\n",
    "y = y.values.ravel()\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], \n",
    "                     'gamma': [2**-12, 2**-11, 2**-10, 2**-19, 2**-8, 2**-7, 2**-6, 2**-5, 2**-4, 2**-3, 2**-2, 2**-1, 1, 2, 4],\n",
    "                     'C': [2**-2, 2**-1, 2**0, 2**1, 2**2, 2**3, 2**4, 2**5, 2**6, 2**7, 2**8, 2**9]}]\n",
    "\n",
    "# scores = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "# print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "# print()\n",
    "# clf = GridSearchCV(SVC(), tuned_parameters, scoring='%s_macro' % score, cv=5)\n",
    "\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, scoring='accuracy', cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_score_, clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.4f for %r\" % (mean, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(confusion_matrix)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print('==========================================================================')\n",
    "\n",
    "    \n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=16, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.00390625, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(15,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "male: \n",
    "18: 0.3893\n",
    "19.2: 0.408, 0.3860(0.38608448623042824 {'C': 2, 'gamma': 0.0625, 'kernel': 'rbf'})\n",
    "20: 0.4428, 0.4026\n",
    "\n",
    "female:\n",
    "30: 0.4555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:112 size of testing set:38\n",
      "Best score:0.97\n",
      "Best parameters:{'gamma': 0.001, 'C': 100}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "iris = load_iris()\n",
    "X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target,random_state=0)\n",
    "print(\"Size of training set:{} size of testing set:{}\".format(X_train.shape[0],X_test.shape[0]))\n",
    " \n",
    "####   grid search start\n",
    "best_score = 0\n",
    "for gamma in [0.001,0.01,0.1,1,10,100]:\n",
    "    for C in [0.001,0.01,0.1,1,10,100]:\n",
    "        svm = SVC(gamma=gamma,C=C)#对于每种参数可能的组合，进行一次训练；\n",
    "        svm.fit(X_train,y_train)\n",
    "        score = svm.score(X_test,y_test)\n",
    "        if score > best_score:#找到表现最好的参数\n",
    "            best_score = score\n",
    "            best_parameters = {'gamma':gamma,'C':C}\n",
    "####   grid search end\n",
    " \n",
    "print(\"Best score:{:.2f}\".format(best_score))\n",
    "print(\"Best parameters:{}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [1074] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2088, 1076) (2088, 312)\n",
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-108d5fd89aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%s_macro'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# 讀入sklearn的範例資料\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "#  資料預處理\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)  #  1797筆\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target\n",
    "\n",
    "# 資料切割訓練與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# 要給gv的參數，可以看到正規化的惩法給了四個，gamma也給了兩個 kernel也用了rbf跟liner\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "#  評估模型的計算得分設置了兩個，並用迴圈來執行這個gv\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    #  以5折下去做暴力尋參，用svc來做分類器\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    #  列印最佳參數\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    #  設置陣列的資料，記得參閱api\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    #  這邊依設置的參數列印出所有參數的得分狀況\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [2, 0, 2, 2, 0, 1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2088, 1076) (2088, 312)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [1074] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "X, y = Scaler(df1_M)\n",
    "X_new = FeatureSelection(X, y, 29)\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(data):\n",
    "    X = data[cname]\n",
    "    y = data[['label']]\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X)\n",
    "    X_std = sc.transform(X)\n",
    "    \n",
    "    clf = SVC()\n",
    "    result = cross_val_score(clf, X_std, y, cv=5, scoring='accuracy')\n",
    "    print (sum(result)/5)\n",
    "    \n",
    "CrossValidation(df1_M)\n",
    "CrossValidation(df1_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: UserWarning: Features [ 0 32 39] are constant.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1797, 7)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "X, y = load_digits(return_X_y=True)\n",
    "X.shape\n",
    "# (1797, 64)\n",
    "X_new = SelectPercentile(f_classif, percentile=10).fit_transform(X, y)\n",
    "X_new.shape\n",
    "# (1797, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Compare to the weights of an SVM\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X, y)\n",
    "\n",
    "svm_weights = (clf.coef_ ** 2).sum(axis=0)\n",
    "svm_weights /= svm_weights.max()\n",
    "\n",
    "plt.bar(X_indices - .25, svm_weights, width=.2, label='SVM weight', color='r')\n",
    "\n",
    "clf_selected = svm.SVC(kernel='linear')\n",
    "clf_selected.fit(selector.transform(X), y)\n",
    "\n",
    "svm_weights_selected = (clf_selected.coef_ ** 2).sum(axis=0)\n",
    "svm_weights_selected /= svm_weights_selected.max()\n",
    "\n",
    "plt.bar(X_indices[selector.get_support()] - .05, svm_weights_selected,\n",
    "        width=.2, label='SVM weights after selection', color='b')\n",
    "\n",
    "\n",
    "plt.title(\"Comparing feature selection\")\n",
    "plt.xlabel('Feature number')\n",
    "plt.yticks(())\n",
    "plt.axis('tight')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
